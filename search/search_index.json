{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"concurrent","text":"<p>Tiny, practical Go concurrency helpers</p> <p>A lightweight Go library providing essential concurrency patterns and utilities for building robust concurrent applications.</p>"},{"location":"#features","title":"Features","text":""},{"location":"#worker-pool","title":"\ud83c\udfaf Worker Pool","text":"<p>Simple fan-out/fan-in pattern with <code>context</code> cancellation support. Process jobs concurrently with a fixed number of workers.</p>"},{"location":"#pipeline","title":"\ud83d\udd04 Pipeline","text":"<p>Composable channel stages (<code>Map</code>, <code>Filter</code>, <code>Batch</code>) with clean cancellation. Build data processing pipelines that are easy to reason about.</p>"},{"location":"#mapconcurrent","title":"\u26a1 MapConcurrent","text":"<p>Bounded parallelism over a slice. Process collections concurrently while maintaining order and respecting cancellation.</p>"},{"location":"#fan-outin","title":"\ud83c\udf0a Fan Out/In","text":"<p>Distribute work across multiple workers and merge results efficiently. Includes round-robin distribution strategies.</p>"},{"location":"#rate-limiting","title":"\ud83d\udea6 Rate Limiting","text":"<p>Token bucket rate limiting with burst support. Control the rate of operations to prevent overwhelming downstream systems.</p>"},{"location":"#retry-circuit-breaker","title":"\ud83d\udd01 Retry &amp; Circuit Breaker","text":"<p>Exponential backoff retry logic with configurable policies. Circuit breaker pattern for handling cascading failures.</p>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n\n    \"github.com/logimos/concurrent\"\n)\n\nfunc main() {\n    ctx := context.Background()\n\n    // Process 100 numbers concurrently with 10 workers\n    data := make([]int, 100)\n    for i := range data {\n        data[i] = i\n    }\n\n    results, err := concurrent.MapConcurrent(ctx, data, 10, func(ctx context.Context, n int) (int, error) {\n        return n * n, nil\n    })\n\n    if err != nil {\n        panic(err)\n    }\n\n    fmt.Println(results)\n}\n</code></pre>"},{"location":"#why-concurrent","title":"Why concurrent?","text":"<ul> <li>Simple API: Easy to understand and use</li> <li>Context-aware: Proper cancellation support throughout</li> <li>Type-safe: Leverages Go generics for type safety</li> <li>Lightweight: Minimal dependencies, fast compilation</li> <li>Production-ready: Well-tested and battle-tested patterns</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code>go get github.com/logimos/concurrent\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li>Getting Started - Installation and setup</li> <li>Features - Detailed feature documentation</li> <li>Examples - Code examples and patterns</li> <li>API Reference - Complete API documentation</li> </ul>"},{"location":"#license","title":"License","text":"<p>See LICENSE file for details.</p>"},{"location":"api/","title":"API Reference","text":"<p>Complete API documentation for the <code>concurrent</code> package.</p>"},{"location":"api/#package-overview","title":"Package Overview","text":"<p>Package <code>concurrent</code> provides concurrency helpers for Go applications.</p>"},{"location":"api/#types","title":"Types","text":""},{"location":"api/#pool","title":"Pool","text":"<pre><code>type Pool[T any, R any] struct {\n    // ...\n}\n</code></pre> <p>Worker pool for concurrent job processing.</p> <p>Methods: - <code>NewPool[T, R](n int, fn func(context.Context, T) (R, error)) *Pool[T, R]</code> - <code>Run(ctx context.Context, jobs &lt;-chan T) &lt;-chan R</code></p>"},{"location":"api/#pipeline","title":"Pipeline","text":"<pre><code>type Pipeline[T any] struct {\n    // ...\n}\n</code></pre> <p>Composable data processing pipeline.</p> <p>Methods: - <code>NewPipeline[T](ctx context.Context) *Pipeline[T]</code> - <code>AddStage(stage Stage[T, T]) *Pipeline[T]</code> - <code>Run(input &lt;-chan T) &lt;-chan T</code> - <code>Close()</code></p>"},{"location":"api/#pipelinebuilder","title":"PipelineBuilder","text":"<pre><code>type PipelineBuilder[T any] struct {\n    // ...\n}\n</code></pre> <p>Fluent builder for pipelines.</p> <p>Methods: - <code>NewPipelineBuilder[T](ctx context.Context) *PipelineBuilder[T]</code> - <code>AddStage(stage Stage[T, T]) *PipelineBuilder[T]</code> - <code>Build() *Pipeline[T]</code></p>"},{"location":"api/#ratelimiter","title":"RateLimiter","text":"<pre><code>type RateLimiter struct {\n    // ...\n}\n</code></pre> <p>Token bucket rate limiter.</p> <p>Methods: - <code>NewRateLimiter(limit int, interval time.Duration) *RateLimiter</code> - <code>Allow() bool</code> - <code>Wait(ctx context.Context) error</code> - <code>Refill()</code></p>"},{"location":"api/#burstratelimit","title":"BurstRateLimit","text":"<pre><code>type BurstRateLimit struct {\n    // ...\n}\n</code></pre> <p>Burst-capable rate limiter.</p> <p>Methods: - <code>NewBurstRateLimit(limit int, interval time.Duration, burst int) *BurstRateLimit</code> - <code>Allow() bool</code> - <code>Wait(ctx context.Context) error</code> - <code>Refill()</code></p>"},{"location":"api/#retryconfig","title":"RetryConfig","text":"<pre><code>type RetryConfig struct {\n    MaxRetries int\n    BaseDelay  time.Duration\n    MaxDelay   time.Duration\n    Multiplier float64\n    Jitter     bool\n}\n</code></pre> <p>Configuration for retry behavior.</p>"},{"location":"api/#circuitbreaker","title":"CircuitBreaker","text":"<pre><code>type CircuitBreaker struct {\n    // ...\n}\n</code></pre> <p>Circuit breaker for failure handling.</p> <p>Methods: - <code>NewCircuitBreaker(failureThreshold int, resetTimeout time.Duration) *CircuitBreaker</code> - <code>Execute(ctx context.Context, fn func() error) error</code> - <code>State() CircuitState</code></p>"},{"location":"api/#circuitstate","title":"CircuitState","text":"<pre><code>type CircuitState int\n</code></pre> <p>Circuit breaker state.</p> <p>Constants: - <code>StateClosed</code> - <code>StateOpen</code> - <code>StateHalfOpen</code></p>"},{"location":"api/#functions","title":"Functions","text":""},{"location":"api/#mapconcurrent","title":"MapConcurrent","text":"<pre><code>func MapConcurrent[T any, R any](\n    ctx context.Context,\n    in []T,\n    n int,\n    fn func(context.Context, T) (R, error),\n) ([]R, error)\n</code></pre> <p>Processes a slice concurrently with bounded parallelism.</p>"},{"location":"api/#fanout","title":"FanOut","text":"<pre><code>func FanOut[T any, R any](\n    ctx context.Context,\n    input &lt;-chan T,\n    workers int,\n    fn func(context.Context, T) (R, error),\n) &lt;-chan R\n</code></pre> <p>Distributes work to multiple workers.</p>"},{"location":"api/#fanin","title":"FanIn","text":"<pre><code>func FanIn[T any](\n    ctx context.Context,\n    inputs ...&lt;-chan T,\n) &lt;-chan T\n</code></pre> <p>Merges multiple input channels.</p>"},{"location":"api/#fanoutfanin","title":"FanOutFanIn","text":"<pre><code>func FanOutFanIn[T any, R any](\n    ctx context.Context,\n    input &lt;-chan T,\n    workers int,\n    fn func(context.Context, T) (R, error),\n) &lt;-chan R\n</code></pre> <p>Combines fan-out and fan-in.</p>"},{"location":"api/#roundrobin","title":"RoundRobin","text":"<pre><code>func RoundRobin[T any, R any](\n    ctx context.Context,\n    input &lt;-chan T,\n    workers int,\n    fn func(context.Context, T) (R, error),\n) &lt;-chan R\n</code></pre> <p>Distributes work in round-robin fashion.</p>"},{"location":"api/#ratelimit","title":"RateLimit","text":"<pre><code>func RateLimit[T any](\n    ctx context.Context,\n    input &lt;-chan T,\n    limit int,\n    interval time.Duration,\n) &lt;-chan T\n</code></pre> <p>Rate limits a channel of items.</p>"},{"location":"api/#retry","title":"Retry","text":"<pre><code>func Retry[T any](\n    ctx context.Context,\n    item T,\n    fn RetryableFunc[T],\n    config RetryConfig,\n) error\n</code></pre> <p>Executes a function with retry logic.</p>"},{"location":"api/#retrywithbackoff","title":"RetryWithBackoff","text":"<pre><code>func RetryWithBackoff[T any](\n    ctx context.Context,\n    item T,\n    fn RetryableFunc[T],\n    maxRetries int,\n    baseDelay time.Duration,\n) error\n</code></pre> <p>Retries with exponential backoff.</p>"},{"location":"api/#retryforever","title":"RetryForever","text":"<pre><code>func RetryForever[T any](\n    ctx context.Context,\n    item T,\n    fn RetryableFunc[T],\n    baseDelay time.Duration,\n) error\n</code></pre> <p>Retries indefinitely until success.</p>"},{"location":"api/#withretry","title":"WithRetry","text":"<pre><code>func WithRetry[T any](\n    fn RetryableFunc[T],\n    config RetryConfig,\n) RetryableFunc[T]\n</code></pre> <p>Wraps a function with retry logic.</p>"},{"location":"api/#defaultretryconfig","title":"DefaultRetryConfig","text":"<pre><code>func DefaultRetryConfig() RetryConfig\n</code></pre> <p>Returns default retry configuration.</p>"},{"location":"api/#newretryableerror","title":"NewRetryableError","text":"<pre><code>func NewRetryableError(err error, retryable bool) RetryableError\n</code></pre> <p>Creates a retryable error.</p>"},{"location":"api/#isretryable","title":"IsRetryable","text":"<pre><code>func IsRetryable(err error) bool\n</code></pre> <p>Checks if an error is retryable.</p>"},{"location":"api/#pipeline-stages","title":"Pipeline Stages","text":""},{"location":"api/#map","title":"Map","text":"<pre><code>func Map[T any](fn func(T) T) Stage[T, T]\n</code></pre> <p>Applies a function to each item.</p>"},{"location":"api/#filter","title":"Filter","text":"<pre><code>func Filter[T any](predicate func(T) bool) Stage[T, T]\n</code></pre> <p>Filters items based on a predicate.</p>"},{"location":"api/#batch","title":"Batch","text":"<pre><code>func Batch[T any](size int) Stage[T, []T]\n</code></pre> <p>Batches items into slices.</p>"},{"location":"api/#unbatch","title":"Unbatch","text":"<pre><code>func Unbatch[T any]() Stage[[]T, T]\n</code></pre> <p>Unbatches slices into individual items.</p>"},{"location":"api/#tee","title":"Tee","text":"<pre><code>func Tee[T any](outputs ...chan&lt;- T) Stage[T, T]\n</code></pre> <p>Splits input to multiple outputs.</p>"},{"location":"api/#merge","title":"Merge","text":"<pre><code>func Merge[T any](ctx context.Context, inputs ...&lt;-chan T) &lt;-chan T\n</code></pre> <p>Merges multiple inputs into one output.</p>"},{"location":"api/#type-aliases","title":"Type Aliases","text":""},{"location":"api/#stage","title":"Stage","text":"<pre><code>type Stage[T any, R any] func(context.Context, &lt;-chan T) &lt;-chan R\n</code></pre> <p>A pipeline stage transformation function.</p>"},{"location":"api/#retryablefunc","title":"RetryableFunc","text":"<pre><code>type RetryableFunc[T any] func(context.Context, T) error\n</code></pre> <p>A function that can be retried.</p>"},{"location":"api/#retryableerror","title":"RetryableError","text":"<pre><code>type RetryableError struct {\n    Err       error\n    Retryable bool\n}\n</code></pre> <p>An error that indicates retryability.</p>"},{"location":"examples/","title":"Examples","text":"<p>This section provides practical examples demonstrating how to use the <code>concurrent</code> package in real-world scenarios.</p>"},{"location":"examples/#available-examples","title":"Available Examples","text":"<ul> <li>Worker Pool - Basic worker pool usage</li> <li>Pipeline - Building data processing pipelines</li> <li>MapReduce - Concurrent map operations</li> </ul>"},{"location":"examples/#running-examples","title":"Running Examples","text":"<p>All examples can be found in the <code>examples/</code> directory. To run an example:</p> <pre><code># Worker Pool example\ncd examples/pool\ngo run main.go\n\n# Pipeline example\ncd examples/pipeline\ngo run main.go\n\n# MapReduce example\ncd examples/mapreduce\ngo run main.go\n</code></pre>"},{"location":"examples/#common-patterns","title":"Common Patterns","text":""},{"location":"examples/#error-handling","title":"Error Handling","text":"<p>When using concurrent operations, always handle errors appropriately:</p> <pre><code>results, err := concurrent.MapConcurrent(ctx, data, 10, func(ctx context.Context, item Item) (Result, error) {\n    result, err := process(item)\n    if err != nil {\n        return Result{}, err\n    }\n    return result, nil\n})\n\nif err != nil {\n    log.Fatalf(\"Processing failed: %v\", err)\n}\n</code></pre>"},{"location":"examples/#context-cancellation","title":"Context Cancellation","text":"<p>Always use contexts with timeouts or cancellation:</p> <pre><code>ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)\ndefer cancel()\n\nresults := pool.Run(ctx, jobs)\n</code></pre>"},{"location":"examples/#resource-cleanup","title":"Resource Cleanup","text":"<p>Ensure proper cleanup of resources:</p> <pre><code>pipeline := concurrent.NewPipeline[int](ctx)\ndefer pipeline.Close()\n\noutput := pipeline.Run(input)\n</code></pre>"},{"location":"examples/mapreduce/","title":"MapReduce Example","text":"<p>This example demonstrates how to use <code>MapConcurrent</code> for concurrent map operations.</p>"},{"location":"examples/mapreduce/#basic-example","title":"Basic Example","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n\n    \"github.com/logimos/concurrent\"\n)\n\nfunc main() {\n    ctx := context.Background()\n\n    data := []int{1, 2, 3, 4, 5, 6}\n    out, err := concurrent.MapConcurrent(ctx, data, 3, func(ctx context.Context, v int) (int, error) {\n        return v * v, nil\n    })\n    if err != nil {\n        panic(err)\n    }\n    fmt.Println(out) // [1 4 9 16 25 36]\n}\n</code></pre>"},{"location":"examples/mapreduce/#example-processing-urls","title":"Example: Processing URLs","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"io\"\n    \"net/http\"\n    \"time\"\n\n    \"github.com/logimos/concurrent\"\n)\n\ntype URLResult struct {\n    URL        string\n    StatusCode int\n    Size       int64\n    Error      error\n}\n\nfunc main() {\n    ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)\n    defer cancel()\n\n    urls := []string{\n        \"https://example.com\",\n        \"https://google.com\",\n        \"https://github.com\",\n        \"https://golang.org\",\n    }\n\n    results, err := concurrent.MapConcurrent(ctx, urls, 5, func(ctx context.Context, url string) (URLResult, error) {\n        req, err := http.NewRequestWithContext(ctx, \"GET\", url, nil)\n        if err != nil {\n            return URLResult{URL: url, Error: err}, nil\n        }\n\n        resp, err := http.DefaultClient.Do(req)\n        if err != nil {\n            return URLResult{URL: url, Error: err}, nil\n        }\n        defer resp.Body.Close()\n\n        size, _ := io.Copy(io.Discard, resp.Body)\n\n        return URLResult{\n            URL:        url,\n            StatusCode: resp.StatusCode,\n            Size:       size,\n        }, nil\n    })\n\n    if err != nil {\n        fmt.Printf(\"Error: %v\\n\", err)\n        return\n    }\n\n    for _, result := range results {\n        if result.Error != nil {\n            fmt.Printf(\"%s: ERROR - %v\\n\", result.URL, result.Error)\n        } else {\n            fmt.Printf(\"%s: %d (%d bytes)\\n\", result.URL, result.StatusCode, result.Size)\n        }\n    }\n}\n</code></pre>"},{"location":"examples/mapreduce/#example-file-processing","title":"Example: File Processing","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"os\"\n    \"path/filepath\"\n\n    \"github.com/logimos/concurrent\"\n)\n\ntype FileResult struct {\n    Path    string\n    Size    int64\n    IsDir   bool\n    Error   error\n}\n\nfunc main() {\n    ctx := context.Background()\n\n    paths := []string{\n        \"/usr/bin\",\n        \"/etc\",\n        \"/tmp\",\n    }\n\n    results, err := concurrent.MapConcurrent(ctx, paths, 10, func(ctx context.Context, path string) (FileResult, error) {\n        info, err := os.Stat(path)\n        if err != nil {\n            return FileResult{Path: path, Error: err}, nil\n        }\n\n        return FileResult{\n            Path:  path,\n            Size:  info.Size(),\n            IsDir: info.IsDir(),\n        }, nil\n    })\n\n    if err != nil {\n        fmt.Printf(\"Error: %v\\n\", err)\n        return\n    }\n\n    for _, result := range results {\n        if result.Error != nil {\n            fmt.Printf(\"%s: ERROR - %v\\n\", result.Path, result.Error)\n        } else {\n            fileType := \"file\"\n            if result.IsDir {\n                fileType = \"directory\"\n            }\n            fmt.Printf(\"%s: %s (%d bytes)\\n\", result.Path, fileType, result.Size)\n        }\n    }\n}\n</code></pre>"},{"location":"examples/mapreduce/#example-data-transformation","title":"Example: Data Transformation","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"strings\"\n\n    \"github.com/logimos/concurrent\"\n)\n\ntype User struct {\n    Name  string\n    Email string\n}\n\ntype ProcessedUser struct {\n    Name      string\n    Email     string\n    Domain    string\n    NameUpper string\n}\n\nfunc main() {\n    ctx := context.Background()\n\n    users := []User{\n        {Name: \"Alice\", Email: \"alice@example.com\"},\n        {Name: \"Bob\", Email: \"bob@example.com\"},\n        {Name: \"Charlie\", Email: \"charlie@test.com\"},\n    }\n\n    results, err := concurrent.MapConcurrent(ctx, users, 3, func(ctx context.Context, user User) (ProcessedUser, error) {\n        parts := strings.Split(user.Email, \"@\")\n        domain := \"\"\n        if len(parts) == 2 {\n            domain = parts[1]\n        }\n\n        return ProcessedUser{\n            Name:      user.Name,\n            Email:     user.Email,\n            Domain:    domain,\n            NameUpper: strings.ToUpper(user.Name),\n        }, nil\n    })\n\n    if err != nil {\n        panic(err)\n    }\n\n    for _, result := range results {\n        fmt.Printf(\"%s (%s) - Domain: %s\\n\", result.NameUpper, result.Email, result.Domain)\n    }\n}\n</code></pre>"},{"location":"examples/pipeline/","title":"Pipeline Example","text":"<p>This example demonstrates how to build data processing pipelines using the <code>Pipeline</code> type.</p>"},{"location":"examples/pipeline/#basic-example","title":"Basic Example","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n\n    \"github.com/logimos/concurrent\"\n)\n\nfunc main() {\n    ctx := context.Background()\n\n    input := make(chan int)\n    pipeline := concurrent.NewPipeline[int](ctx)\n\n    // Multiply by 2\n    pipeline.AddStage(concurrent.Map(func(n int) int {\n        return n * 2\n    }))\n\n    // Filter even numbers\n    pipeline.AddStage(concurrent.Filter(func(n int) bool {\n        return n%2 == 0\n    }))\n\n    output := pipeline.Run(input)\n\n    // Send data\n    go func() {\n        for i := 1; i &lt;= 10; i++ {\n            input &lt;- i\n        }\n        close(input)\n    }()\n\n    // Process results\n    for result := range output {\n        fmt.Println(result)\n    }\n\n    pipeline.Close()\n}\n</code></pre>"},{"location":"examples/pipeline/#example-data-transformation-pipeline","title":"Example: Data Transformation Pipeline","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"strings\"\n\n    \"github.com/logimos/concurrent\"\n)\n\ntype Data struct {\n    Text string\n    Len  int\n}\n\nfunc main() {\n    ctx := context.Background()\n\n    input := make(chan string)\n    pipeline := concurrent.NewPipeline[string](ctx)\n\n    // Transform: uppercase\n    pipeline.AddStage(concurrent.Map(func(s string) string {\n        return strings.ToUpper(s)\n    }))\n\n    // Filter: keep only long strings\n    pipeline.AddStage(concurrent.Map(func(s string) Data {\n        return Data{Text: s, Len: len(s)}\n    }))\n\n    pipeline.AddStage(concurrent.Filter(func(d Data) bool {\n        return d.Len &gt; 5\n    }))\n\n    output := pipeline.Run(input)\n\n    go func() {\n        input &lt;- \"hello\"\n        input &lt;- \"world\"\n        input &lt;- \"go\"\n        input &lt;- \"pipeline\"\n        close(input)\n    }()\n\n    for result := range output {\n        fmt.Printf(\"%s (%d chars)\\n\", result.Text, result.Len)\n    }\n\n    pipeline.Close()\n}\n</code></pre>"},{"location":"examples/pipeline/#example-batching-pipeline","title":"Example: Batching Pipeline","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n\n    \"github.com/logimos/concurrent\"\n)\n\nfunc main() {\n    ctx := context.Background()\n\n    input := make(chan int)\n    pipeline := concurrent.NewPipeline[int](ctx)\n\n    // Square each number\n    pipeline.AddStage(concurrent.Map(func(n int) int {\n        return n * n\n    }))\n\n    // Batch into groups of 5\n    pipeline.AddStage(concurrent.Batch[int](5))\n\n    output := pipeline.Run(input)\n\n    go func() {\n        for i := 1; i &lt;= 12; i++ {\n            input &lt;- i\n        }\n        close(input)\n    }()\n\n    for batch := range output {\n        fmt.Println(batch)\n    }\n\n    pipeline.Close()\n}\n</code></pre> <p>Output: <pre><code>[1 4 9 16 25]\n[36 49 64 81 100]\n[121 144]\n</code></pre></p>"},{"location":"examples/pipeline/#example-using-pipeline-builder","title":"Example: Using Pipeline Builder","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n\n    \"github.com/logimos/concurrent\"\n)\n\nfunc main() {\n    ctx := context.Background()\n\n    input := make(chan int)\n\n    pipeline := concurrent.NewPipelineBuilder[int](ctx).\n        AddStage(concurrent.Map(func(n int) int { return n * 2 })).\n        AddStage(concurrent.Filter(func(n int) bool { return n &gt; 10 })).\n        AddStage(concurrent.Batch[int](3)).\n        Build()\n\n    output := pipeline.Run(input)\n\n    go func() {\n        for i := 1; i &lt;= 10; i++ {\n            input &lt;- i\n        }\n        close(input)\n    }()\n\n    for batch := range output {\n        fmt.Println(batch)\n    }\n\n    pipeline.Close()\n}\n</code></pre>"},{"location":"examples/pool/","title":"Worker Pool Example","text":"<p>This example demonstrates how to use the <code>Pool</code> type to process jobs concurrently.</p>"},{"location":"examples/pool/#basic-example","title":"Basic Example","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"time\"\n\n    \"github.com/logimos/concurrent\"\n)\n\nfunc main() {\n    ctx := context.Background()\n\n    jobs := make(chan int)\n    pool := concurrent.NewPool(3, func(ctx context.Context, v int) (string, error) {\n        time.Sleep(15 * time.Millisecond)\n        return fmt.Sprintf(\"processed-%d\", v), nil\n    })\n    results := pool.Run(ctx, jobs)\n\n    go func() {\n        for i := 0; i &lt; 8; i++ {\n            jobs &lt;- i\n        }\n        close(jobs)\n    }()\n\n    for r := range results {\n        fmt.Println(r)\n    }\n}\n</code></pre>"},{"location":"examples/pool/#output","title":"Output","text":"<pre><code>processed-0\nprocessed-1\nprocessed-2\nprocessed-3\nprocessed-4\nprocessed-5\nprocessed-6\nprocessed-7\n</code></pre>"},{"location":"examples/pool/#advanced-example-http-requests","title":"Advanced Example: HTTP Requests","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"io\"\n    \"net/http\"\n    \"time\"\n\n    \"github.com/logimos/concurrent\"\n)\n\ntype Result struct {\n    URL    string\n    Status int\n    Error  error\n}\n\nfunc main() {\n    ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)\n    defer cancel()\n\n    urls := []string{\n        \"https://example.com\",\n        \"https://google.com\",\n        \"https://github.com\",\n    }\n\n    jobs := make(chan string)\n    pool := concurrent.NewPool(5, func(ctx context.Context, url string) (Result, error) {\n        req, err := http.NewRequestWithContext(ctx, \"GET\", url, nil)\n        if err != nil {\n            return Result{URL: url, Error: err}, nil\n        }\n\n        resp, err := http.DefaultClient.Do(req)\n        if err != nil {\n            return Result{URL: url, Error: err}, nil\n        }\n        defer resp.Body.Close()\n\n        // Read body to ensure connection is fully consumed\n        io.Copy(io.Discard, resp.Body)\n\n        return Result{\n            URL:    url,\n            Status: resp.StatusCode,\n        }, nil\n    })\n\n    results := pool.Run(ctx, jobs)\n\n    // Send jobs\n    go func() {\n        for _, url := range urls {\n            jobs &lt;- url\n        }\n        close(jobs)\n    }()\n\n    // Collect results\n    for r := range results {\n        if r.Error != nil {\n            fmt.Printf(\"%s: ERROR - %v\\n\", r.URL, r.Error)\n        } else {\n            fmt.Printf(\"%s: %d\\n\", r.URL, r.Status)\n        }\n    }\n}\n</code></pre>"},{"location":"examples/pool/#example-file-processing","title":"Example: File Processing","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"os\"\n    \"path/filepath\"\n\n    \"github.com/logimos/concurrent\"\n)\n\ntype FileInfo struct {\n    Path string\n    Size int64\n    Err  error\n}\n\nfunc main() {\n    ctx := context.Background()\n\n    files := []string{\n        \"/path/to/file1.txt\",\n        \"/path/to/file2.txt\",\n        \"/path/to/file3.txt\",\n    }\n\n    jobs := make(chan string)\n    pool := concurrent.NewPool(10, func(ctx context.Context, path string) (FileInfo, error) {\n        info, err := os.Stat(path)\n        if err != nil {\n            return FileInfo{Path: path, Err: err}, nil\n        }\n\n        return FileInfo{\n            Path: path,\n            Size: info.Size(),\n        }, nil\n    })\n\n    results := pool.Run(ctx, jobs)\n\n    go func() {\n        for _, file := range files {\n            jobs &lt;- file\n        }\n        close(jobs)\n    }()\n\n    totalSize := int64(0)\n    for r := range results {\n        if r.Err != nil {\n            fmt.Printf(\"Error processing %s: %v\\n\", r.Path, r.Err)\n        } else {\n            fmt.Printf(\"%s: %d bytes\\n\", r.Path, r.Size)\n            totalSize += r.Size\n        }\n    }\n\n    fmt.Printf(\"Total size: %d bytes\\n\", totalSize)\n}\n</code></pre>"},{"location":"features/fan/","title":"Fan Out/In","text":"<p>Fan-out/fan-in patterns distribute work across multiple workers and merge results efficiently. The <code>concurrent</code> package provides several variants for different distribution strategies.</p>"},{"location":"features/fan/#overview","title":"Overview","text":"<ul> <li>FanOut: Distributes work from a single input channel to multiple workers</li> <li>FanIn: Merges multiple input channels into a single output channel</li> <li>FanOutFanIn: Combines both patterns for parallel processing</li> <li>RoundRobin: Distributes work in round-robin fashion</li> </ul>"},{"location":"features/fan/#fanout","title":"FanOut","text":"<p>Distributes work from a single input channel to multiple workers, each processing items concurrently.</p>"},{"location":"features/fan/#example","title":"Example","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n\n    \"github.com/logimos/concurrent\"\n)\n\nfunc main() {\n    ctx := context.Background()\n\n    input := make(chan int)\n\n    // Process with 5 workers\n    output := concurrent.FanOut(ctx, input, 5, func(ctx context.Context, n int) (int, error) {\n        return n * n, nil\n    })\n\n    // Send work\n    go func() {\n        for i := 1; i &lt;= 10; i++ {\n            input &lt;- i\n        }\n        close(input)\n    }()\n\n    // Collect results\n    for result := range output {\n        fmt.Println(result)\n    }\n}\n</code></pre>"},{"location":"features/fan/#api","title":"API","text":"<pre><code>func FanOut[T any, R any](ctx context.Context, input &lt;-chan T, workers int, fn func(context.Context, T) (R, error)) &lt;-chan R\n</code></pre> <p>Parameters: - <code>ctx</code>: Context for cancellation - <code>input</code>: Input channel of work items - <code>workers</code>: Number of worker goroutines - <code>fn</code>: Processing function</p> <p>Returns: Output channel of results</p>"},{"location":"features/fan/#fanin","title":"FanIn","text":"<p>Merges multiple input channels into a single output channel.</p>"},{"location":"features/fan/#example_1","title":"Example","text":"<pre><code>ch1 := make(chan int)\nch2 := make(chan int)\nch3 := make(chan int)\n\noutput := concurrent.FanIn(ctx, ch1, ch2, ch3)\n\n// Send to channels\ngo func() { ch1 &lt;- 1; close(ch1) }()\ngo func() { ch2 &lt;- 2; close(ch2) }()\ngo func() { ch3 &lt;- 3; close(ch3) }()\n\n// Collect merged results\nfor result := range output {\n    fmt.Println(result) // Order may vary\n}\n</code></pre>"},{"location":"features/fan/#api_1","title":"API","text":"<pre><code>func FanIn[T any](ctx context.Context, inputs ...&lt;-chan T) &lt;-chan T\n</code></pre> <p>Parameters: - <code>ctx</code>: Context for cancellation - <code>inputs</code>: Variable number of input channels</p> <p>Returns: Merged output channel</p>"},{"location":"features/fan/#fanoutfanin","title":"FanOutFanIn","text":"<p>Combines fan-out and fan-in for parallel processing with result merging.</p>"},{"location":"features/fan/#example_2","title":"Example","text":"<pre><code>input := make(chan string)\n\n// Process with 3 workers and merge results\noutput := concurrent.FanOutFanIn(ctx, input, 3, func(ctx context.Context, s string) (string, error) {\n    return strings.ToUpper(s), nil\n})\n\ngo func() {\n    input &lt;- \"hello\"\n    input &lt;- \"world\"\n    close(input)\n}()\n\nfor result := range output {\n    fmt.Println(result)\n}\n</code></pre>"},{"location":"features/fan/#api_2","title":"API","text":"<pre><code>func FanOutFanIn[T any, R any](ctx context.Context, input &lt;-chan T, workers int, fn func(context.Context, T) (R, error)) &lt;-chan R\n</code></pre>"},{"location":"features/fan/#roundrobin","title":"RoundRobin","text":"<p>Distributes work in round-robin fashion to multiple workers.</p>"},{"location":"features/fan/#example_3","title":"Example","text":"<pre><code>input := make(chan int)\n\n// Distribute evenly across 4 workers\noutput := concurrent.RoundRobin(ctx, input, 4, func(ctx context.Context, n int) (int, error) {\n    return n * 2, nil\n})\n\ngo func() {\n    for i := 1; i &lt;= 8; i++ {\n        input &lt;- i\n    }\n    close(input)\n}()\n\nfor result := range output {\n    fmt.Println(result)\n}\n</code></pre>"},{"location":"features/fan/#api_3","title":"API","text":"<pre><code>func RoundRobin[T any, R any](ctx context.Context, input &lt;-chan T, workers int, fn func(context.Context, T) (R, error)) &lt;-chan R\n</code></pre> <p>Note: RoundRobin ensures work is distributed evenly across workers, unlike FanOut which distributes work as workers become available.</p>"},{"location":"features/fan/#use-cases","title":"Use Cases","text":""},{"location":"features/fan/#fanout_1","title":"FanOut","text":"<ul> <li>When you want concurrent processing but don't care about work distribution order</li> <li>Processing independent tasks from a single source</li> </ul>"},{"location":"features/fan/#fanin_1","title":"FanIn","text":"<ul> <li>Merging results from multiple processing pipelines</li> <li>Combining outputs from different data sources</li> </ul>"},{"location":"features/fan/#fanoutfanin_1","title":"FanOutFanIn","text":"<ul> <li>Parallel processing with automatic result merging</li> <li>Simplifies the pattern when you need both fan-out and fan-in</li> </ul>"},{"location":"features/fan/#roundrobin_1","title":"RoundRobin","text":"<ul> <li>When you need even work distribution</li> <li>Load balancing across workers</li> </ul>"},{"location":"features/fan/#best-practices","title":"Best Practices","text":"<ol> <li>Close input channels: Always close input channels when done sending</li> <li>Consume output: Read from output channels until closed</li> <li>Handle errors: Errors in processing functions are silently dropped - wrap if needed</li> <li>Use context: Pass contexts with appropriate timeouts</li> <li>Worker count: Choose worker count based on CPU cores and I/O characteristics</li> </ol>"},{"location":"features/fan/#error-handling","title":"Error Handling","text":"<p>By default, errors from processing functions are dropped. To handle errors:</p> <pre><code>type Result struct {\n    Value int\n    Error error\n}\n\noutput := concurrent.FanOut(ctx, input, 5, func(ctx context.Context, n int) (Result, error) {\n    result, err := process(n)\n    return Result{Value: result, Error: err}, nil\n})\n\nfor r := range output {\n    if r.Error != nil {\n        fmt.Printf(\"Error: %v\\n\", r.Error)\n    } else {\n        fmt.Printf(\"Success: %d\\n\", r.Value)\n    }\n}\n</code></pre>"},{"location":"features/mapconcurrent/","title":"MapConcurrent","text":"<p><code>MapConcurrent</code> provides bounded parallelism over a slice, processing elements concurrently while maintaining order and respecting cancellation.</p>"},{"location":"features/mapconcurrent/#overview","title":"Overview","text":"<p><code>MapConcurrent</code> applies a function to each element of a slice with at most <code>n</code> concurrent operations. Results are returned in the original order, and the first error aborts early.</p>"},{"location":"features/mapconcurrent/#usage","title":"Usage","text":""},{"location":"features/mapconcurrent/#basic-example","title":"Basic Example","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n\n    \"github.com/logimos/concurrent\"\n)\n\nfunc main() {\n    ctx := context.Background()\n\n    data := []int{1, 2, 3, 4, 5}\n\n    results, err := concurrent.MapConcurrent(ctx, data, 3, func(ctx context.Context, n int) (int, error) {\n        return n * n, nil\n    })\n\n    if err != nil {\n        panic(err)\n    }\n\n    fmt.Println(results) // [1 4 9 16 25]\n}\n</code></pre>"},{"location":"features/mapconcurrent/#key-features","title":"Key Features","text":"<ul> <li>Order Preservation: Results are returned in the same order as input</li> <li>Bounded Concurrency: Limits the number of concurrent operations</li> <li>Early Abort: First error stops processing</li> <li>Cancellation Support: Respects context cancellation</li> <li>Graceful Shutdown: Waits for in-flight operations to complete</li> </ul>"},{"location":"features/mapconcurrent/#api-reference","title":"API Reference","text":""},{"location":"features/mapconcurrent/#mapconcurrentt-rctx-contextcontext-in-t-n-int-fn-funccontextcontext-t-r-error-r-error","title":"<code>MapConcurrent[T, R](ctx context.Context, in []T, n int, fn func(context.Context, T) (R, error)) ([]R, error)</code>","text":"<p>Applies <code>fn</code> to each element of <code>in</code> with at most <code>n</code> concurrent tasks.</p> <p>Parameters: - <code>ctx</code>: Context for cancellation - <code>in</code>: Input slice - <code>n</code>: Maximum number of concurrent operations (must be &gt; 0, defaults to 1) - <code>fn</code>: Function to apply to each element</p> <p>Returns: - <code>[]R</code>: Results in the same order as input - <code>error</code>: First error encountered, or nil</p>"},{"location":"features/mapconcurrent/#behavior","title":"Behavior","text":""},{"location":"features/mapconcurrent/#concurrency-control","title":"Concurrency Control","text":"<p>The <code>n</code> parameter controls the maximum number of goroutines processing items simultaneously. If <code>n</code> is greater than the slice length, only as many goroutines as needed are started.</p>"},{"location":"features/mapconcurrent/#error-handling","title":"Error Handling","text":"<p>If any function call returns an error: - Processing stops immediately - In-flight operations complete - The error is returned</p>"},{"location":"features/mapconcurrent/#cancellation","title":"Cancellation","text":"<p>When the context is canceled: - No new operations start - In-flight operations complete - <code>ctx.Err()</code> is returned</p>"},{"location":"features/mapconcurrent/#empty-input","title":"Empty Input","text":"<p>If the input slice is empty, an empty result slice and <code>nil</code> error are returned immediately.</p>"},{"location":"features/mapconcurrent/#examples","title":"Examples","text":""},{"location":"features/mapconcurrent/#processing-urls","title":"Processing URLs","text":"<pre><code>type Result struct {\n    URL    string\n    Status int\n}\n\nurls := []string{\"https://example.com\", \"https://google.com\", \"https://github.com\"}\n\nresults, err := concurrent.MapConcurrent(ctx, urls, 5, func(ctx context.Context, url string) (Result, error) {\n    resp, err := http.Get(url)\n    if err != nil {\n        return Result{}, err\n    }\n    defer resp.Body.Close()\n    return Result{URL: url, Status: resp.StatusCode}, nil\n})\n\nif err != nil {\n    log.Fatal(err)\n}\n\nfor _, r := range results {\n    fmt.Printf(\"%s: %d\\n\", r.URL, r.Status)\n}\n</code></pre>"},{"location":"features/mapconcurrent/#with-cancellation","title":"With Cancellation","text":"<pre><code>ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\ndefer cancel()\n\nresults, err := concurrent.MapConcurrent(ctx, data, 10, processFunc)\nif err != nil {\n    if err == context.DeadlineExceeded {\n        fmt.Println(\"Operation timed out\")\n    } else {\n        fmt.Printf(\"Error: %v\\n\", err)\n    }\n}\n</code></pre>"},{"location":"features/mapconcurrent/#error-propagation","title":"Error Propagation","text":"<pre><code>results, err := concurrent.MapConcurrent(ctx, data, 3, func(ctx context.Context, n int) (int, error) {\n    if n &lt; 0 {\n        return 0, fmt.Errorf(\"negative number: %d\", n)\n    }\n    return n * n, nil\n})\n\nif err != nil {\n    // Handle error - processing stopped at first error\n    fmt.Printf(\"Failed: %v\\n\", err)\n    return\n}\n</code></pre>"},{"location":"features/mapconcurrent/#best-practices","title":"Best Practices","text":"<ol> <li>Choose appropriate concurrency: <code>n</code> should balance throughput and resource usage</li> <li>Handle errors: Always check the returned error</li> <li>Use context: Pass contexts with timeouts for long-running operations</li> <li>Idempotent functions: Ensure <code>fn</code> is safe to retry if needed</li> <li>Resource cleanup: Make sure <code>fn</code> properly cleans up resources (connections, files, etc.)</li> </ol>"},{"location":"features/mapconcurrent/#comparison-with-pool","title":"Comparison with Pool","text":"<ul> <li>MapConcurrent: Best for processing a known slice of items, preserves order, early abort on error</li> <li>Pool: Best for processing an unknown stream of jobs from a channel, continues on errors</li> </ul> <p>Choose <code>MapConcurrent</code> when you have a fixed set of items to process. Choose <code>Pool</code> when you have a stream of jobs.</p>"},{"location":"features/pipeline/","title":"Pipeline","text":"<p>The <code>Pipeline</code> type provides composable channel stages for building data processing pipelines. It supports operations like <code>Map</code>, <code>Filter</code>, and <code>Batch</code> with proper cancellation handling.</p>"},{"location":"features/pipeline/#overview","title":"Overview","text":"<p>A pipeline chains together multiple stages, where each stage transforms data flowing through channels. Stages are composable and can be combined to build complex data processing workflows.</p>"},{"location":"features/pipeline/#usage","title":"Usage","text":""},{"location":"features/pipeline/#basic-example","title":"Basic Example","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n\n    \"github.com/logimos/concurrent\"\n)\n\nfunc main() {\n    ctx := context.Background()\n\n    input := make(chan int)\n    pipeline := concurrent.NewPipeline[int](ctx)\n\n    // Add stages\n    pipeline.AddStage(concurrent.Map(func(n int) int {\n        return n * 2\n    }))\n\n    pipeline.AddStage(concurrent.Filter(func(n int) bool {\n        return n &gt; 10\n    }))\n\n    output := pipeline.Run(input)\n\n    // Send data\n    go func() {\n        for i := 1; i &lt;= 10; i++ {\n            input &lt;- i\n        }\n        close(input)\n    }()\n\n    // Process results\n    for result := range output {\n        fmt.Println(result) // 12, 14, 16, 18, 20\n    }\n\n    pipeline.Close()\n}\n</code></pre>"},{"location":"features/pipeline/#pipeline-builder","title":"Pipeline Builder","text":"<p>You can also use the fluent builder pattern:</p> <pre><code>pipeline := concurrent.NewPipelineBuilder[int](ctx).\n    AddStage(concurrent.Map(func(n int) int { return n * 2 })).\n    AddStage(concurrent.Filter(func(n int) bool { return n &gt; 10 })).\n    Build()\n\noutput := pipeline.Run(input)\n</code></pre>"},{"location":"features/pipeline/#available-stages","title":"Available Stages","text":""},{"location":"features/pipeline/#map","title":"Map","text":"<p>Applies a function to each item:</p> <pre><code>pipeline.AddStage(concurrent.Map(func(n int) int {\n    return n * 2\n}))\n</code></pre>"},{"location":"features/pipeline/#filter","title":"Filter","text":"<p>Keeps only items where the predicate returns true:</p> <pre><code>pipeline.AddStage(concurrent.Filter(func(n int) bool {\n    return n &gt; 0\n}))\n</code></pre>"},{"location":"features/pipeline/#batch","title":"Batch","text":"<p>Groups items into slices of a specified size:</p> <pre><code>pipeline.AddStage(concurrent.Batch[int](10))\n</code></pre> <p>Note: The output type changes from <code>T</code> to <code>[]T</code> when using <code>Batch</code>.</p>"},{"location":"features/pipeline/#unbatch","title":"Unbatch","text":"<p>Splits batches back into individual items:</p> <pre><code>pipeline.AddStage(concurrent.Unbatch[int]())\n</code></pre> <p>Note: The input type must be <code>[]T</code> and output type becomes <code>T</code>.</p>"},{"location":"features/pipeline/#tee","title":"Tee","text":"<p>Splits the input to multiple output channels:</p> <pre><code>output1 := make(chan int)\noutput2 := make(chan int)\n\npipeline.AddStage(concurrent.Tee(output1, output2))\n</code></pre> <p>Warning: Tee closes the provided output channels when done. Do not reuse these channels.</p>"},{"location":"features/pipeline/#merge","title":"Merge","text":"<p>Merges multiple input channels into one output:</p> <pre><code>output := concurrent.Merge(ctx, input1, input2, input3)\n</code></pre>"},{"location":"features/pipeline/#advanced-examples","title":"Advanced Examples","text":""},{"location":"features/pipeline/#batching-pipeline","title":"Batching Pipeline","text":"<pre><code>ctx := context.Background()\ninput := make(chan int)\n\npipeline := concurrent.NewPipeline[int](ctx)\npipeline.AddStage(concurrent.Map(func(n int) int { return n * 2 }))\npipeline.AddStage(concurrent.Batch[int](5))\n\noutput := pipeline.Run(input)\n\n// Send data\ngo func() {\n    for i := 1; i &lt;= 12; i++ {\n        input &lt;- i\n    }\n    close(input)\n}()\n\n// Results are batches of 5\nfor batch := range output {\n    fmt.Println(batch) // [2 4 6 8 10], [12 14 16 18 20], [22 24]\n}\n</code></pre>"},{"location":"features/pipeline/#complex-pipeline","title":"Complex Pipeline","text":"<pre><code>pipeline := concurrent.NewPipeline[int](ctx).\n    AddStage(concurrent.Map(func(n int) int { return n * n })).\n    AddStage(concurrent.Filter(func(n int) bool { return n%2 == 0 })).\n    AddStage(concurrent.Batch[int](3)).\n    Build()\n</code></pre>"},{"location":"features/pipeline/#api-reference","title":"API Reference","text":""},{"location":"features/pipeline/#newpipelinetctx-contextcontext-pipelinet","title":"<code>NewPipeline[T](ctx context.Context) *Pipeline[T]</code>","text":"<p>Creates a new pipeline with the given context.</p>"},{"location":"features/pipeline/#addstagestage-staget-t-pipelinet","title":"<code>AddStage(stage Stage[T, T]) *Pipeline[T]</code>","text":"<p>Adds a stage to the pipeline. Returns the pipeline for method chaining.</p>"},{"location":"features/pipeline/#runinput-chan-t-chan-t","title":"<code>Run(input &lt;-chan T) &lt;-chan T</code>","text":"<p>Executes the pipeline with the given input channel. Returns the output channel.</p>"},{"location":"features/pipeline/#close","title":"<code>Close()</code>","text":"<p>Cancels the pipeline context, stopping all stages.</p>"},{"location":"features/pipeline/#staget-r","title":"<code>Stage[T, R]</code>","text":"<p>A stage is a function that transforms an input channel to an output channel:</p> <pre><code>type Stage[T any, R any] func(context.Context, &lt;-chan T) &lt;-chan R\n</code></pre>"},{"location":"features/pipeline/#best-practices","title":"Best Practices","text":"<ol> <li>Always close the pipeline: Call <code>pipeline.Close()</code> when done to clean up resources</li> <li>Consume output: Read from the output channel until it's closed</li> <li>Close input: Close the input channel when done sending data</li> <li>Use context: Pass a context with appropriate timeout or cancellation</li> <li>Type consistency: Ensure stage types match (except for Batch/Unbatch)</li> </ol>"},{"location":"features/pipeline/#cancellation","title":"Cancellation","text":"<p>All stages respect context cancellation. When the pipeline context is canceled: - Stages stop accepting new items - In-flight operations complete gracefully - Output channels are closed properly</p>"},{"location":"features/pool/","title":"Worker Pool","text":"<p>The <code>Pool</code> type provides a simple fan-out/fan-in pattern with a fixed number of workers. It's ideal for processing jobs concurrently while maintaining control over resource usage.</p>"},{"location":"features/pool/#overview","title":"Overview","text":"<p>A worker pool distributes jobs from an input channel to a fixed number of workers, each processing jobs concurrently. Results are collected into a single output channel.</p>"},{"location":"features/pool/#usage","title":"Usage","text":""},{"location":"features/pool/#basic-example","title":"Basic Example","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"time\"\n\n    \"github.com/logimos/concurrent\"\n)\n\nfunc main() {\n    ctx := context.Background()\n\n    jobs := make(chan int)\n    pool := concurrent.NewPool(3, func(ctx context.Context, v int) (string, error) {\n        // Simulate work\n        time.Sleep(100 * time.Millisecond)\n        return fmt.Sprintf(\"processed-%d\", v), nil\n    })\n\n    results := pool.Run(ctx, jobs)\n\n    // Send jobs\n    go func() {\n        for i := 0; i &lt; 10; i++ {\n            jobs &lt;- i\n        }\n        close(jobs)\n    }()\n\n    // Collect results\n    for r := range results {\n        fmt.Println(r)\n    }\n}\n</code></pre>"},{"location":"features/pool/#api-reference","title":"API Reference","text":""},{"location":"features/pool/#newpoolt-rn-int-fn-funccontextcontext-t-r-error-poolt-r","title":"<code>NewPool[T, R](n int, fn func(context.Context, T) (R, error)) *Pool[T, R]</code>","text":"<p>Creates a new pool with <code>n</code> workers and a processing function.</p> <p>Parameters: - <code>n</code>: Number of workers (must be &gt; 0, defaults to 1 if &lt;= 0) - <code>fn</code>: Processing function that takes a context and input value, returns result and error</p> <p>Returns: A new <code>Pool</code> instance</p>"},{"location":"features/pool/#runctx-contextcontext-jobs-chan-t-chan-r","title":"<code>Run(ctx context.Context, jobs &lt;-chan T) &lt;-chan R</code>","text":"<p>Executes jobs until the context is canceled or the jobs channel is closed.</p> <p>Important: The caller MUST consume the results channel until it is closed to prevent goroutine leaks.</p> <p>Parameters: - <code>ctx</code>: Context for cancellation - <code>jobs</code>: Input channel of jobs to process</p> <p>Returns: Output channel of results</p>"},{"location":"features/pool/#behavior","title":"Behavior","text":"<ul> <li>Error Handling: If <code>fn</code> returns an error, that job's result is dropped. Use a wrapper function if you need to propagate per-item errors.</li> <li>Cancellation: The pool respects context cancellation. When <code>ctx</code> is canceled, workers stop accepting new jobs and complete in-flight operations.</li> <li>Channel Closing: When the input channel is closed, workers finish processing remaining jobs and the results channel is closed automatically.</li> </ul>"},{"location":"features/pool/#best-practices","title":"Best Practices","text":"<ol> <li>Always consume results: Make sure to read from the results channel until it's closed</li> <li>Close input channel: Close the jobs channel when done sending to signal completion</li> <li>Use context: Always pass a context with appropriate timeout or cancellation</li> <li>Error handling: Wrap the processing function if you need per-item error handling</li> </ol>"},{"location":"features/pool/#example-error-handling","title":"Example: Error Handling","text":"<pre><code>type Result struct {\n    Value string\n    Error error\n}\n\njobs := make(chan int)\npool := concurrent.NewPool(3, func(ctx context.Context, v int) (Result, error) {\n    result, err := processJob(v)\n    return Result{Value: result, Error: err}, nil\n})\n\nresults := pool.Run(ctx, jobs)\n\nfor r := range results {\n    if r.Error != nil {\n        fmt.Printf(\"Error processing job: %v\\n\", r.Error)\n    } else {\n        fmt.Printf(\"Success: %s\\n\", r.Value)\n    }\n}\n</code></pre>"},{"location":"features/rate-limiting/","title":"Rate Limiting","text":"<p>Rate limiting controls the rate of operations to prevent overwhelming downstream systems. The <code>concurrent</code> package provides token bucket rate limiters with burst support.</p>"},{"location":"features/rate-limiting/#overview","title":"Overview","text":"<p>Rate limiters use a token bucket algorithm: - Tokens are added to the bucket at a fixed rate - Operations consume tokens - Operations wait if no tokens are available</p>"},{"location":"features/rate-limiting/#basic-rate-limiter","title":"Basic Rate Limiter","text":""},{"location":"features/rate-limiting/#example","title":"Example","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"time\"\n\n    \"github.com/logimos/concurrent\"\n)\n\nfunc main() {\n    // Allow 10 operations per second\n    limiter := concurrent.NewRateLimiter(10, time.Second)\n\n    ctx := context.Background()\n\n    for i := 0; i &lt; 20; i++ {\n        if err := limiter.Wait(ctx); err != nil {\n            break\n        }\n\n        // Perform operation\n        fmt.Printf(\"Operation %d\\n\", i)\n    }\n}\n</code></pre>"},{"location":"features/rate-limiting/#api","title":"API","text":""},{"location":"features/rate-limiting/#newratelimiterlimit-int-interval-timeduration-ratelimiter","title":"<code>NewRateLimiter(limit int, interval time.Duration) *RateLimiter</code>","text":"<p>Creates a rate limiter allowing <code>limit</code> operations per <code>interval</code>.</p> <p>Example: <code>NewRateLimiter(100, time.Second)</code> allows 100 operations per second.</p>"},{"location":"features/rate-limiting/#allow-bool","title":"<code>Allow() bool</code>","text":"<p>Checks if an operation is allowed without blocking. Returns <code>true</code> if allowed, <code>false</code> otherwise.</p>"},{"location":"features/rate-limiting/#waitctx-contextcontext-error","title":"<code>Wait(ctx context.Context) error</code>","text":"<p>Blocks until an operation is allowed. Returns an error if the context is canceled.</p> <p>Note: <code>Refill()</code> must be called periodically for tokens to be replenished. See <code>RateLimit()</code> for automatic refill.</p>"},{"location":"features/rate-limiting/#refill","title":"<code>Refill()</code>","text":"<p>Refills the token bucket based on elapsed time. Should be called periodically.</p>"},{"location":"features/rate-limiting/#rate-limit-channel","title":"Rate Limit Channel","text":"<p>The <code>RateLimit</code> function automatically handles token refilling and provides a channel-based interface.</p>"},{"location":"features/rate-limiting/#example_1","title":"Example","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"time\"\n\n    \"github.com/logimos/concurrent\"\n)\n\nfunc main() {\n    ctx := context.Background()\n\n    input := make(chan string)\n\n    // Rate limit to 5 items per second\n    output := concurrent.RateLimit(ctx, input, 5, time.Second)\n\n    // Send items\n    go func() {\n        for i := 0; i &lt; 20; i++ {\n            input &lt;- fmt.Sprintf(\"item-%d\", i)\n        }\n        close(input)\n    }()\n\n    // Process rate-limited items\n    for item := range output {\n        fmt.Println(item)\n    }\n}\n</code></pre>"},{"location":"features/rate-limiting/#api_1","title":"API","text":"<pre><code>func RateLimit[T any](ctx context.Context, input &lt;-chan T, limit int, interval time.Duration) &lt;-chan T\n</code></pre> <p>Parameters: - <code>ctx</code>: Context for cancellation - <code>input</code>: Input channel - <code>limit</code>: Maximum operations per interval - <code>interval</code>: Time interval</p> <p>Returns: Rate-limited output channel</p>"},{"location":"features/rate-limiting/#burst-rate-limiter","title":"Burst Rate Limiter","text":"<p>Burst rate limiters allow bursts up to a maximum size while maintaining an average rate.</p>"},{"location":"features/rate-limiting/#example_2","title":"Example","text":"<pre><code>// Allow bursts of 20, but average 10 per second\nlimiter := concurrent.NewBurstRateLimit(10, time.Second, 20)\n\nctx := context.Background()\n\n// Can process 20 items immediately, then rate-limited\nfor i := 0; i &lt; 30; i++ {\n    if err := limiter.Wait(ctx); err != nil {\n        break\n    }\n    processItem(i)\n}\n</code></pre>"},{"location":"features/rate-limiting/#api_2","title":"API","text":""},{"location":"features/rate-limiting/#newburstratelimitlimit-int-interval-timeduration-burst-int-burstratelimit","title":"<code>NewBurstRateLimit(limit int, interval time.Duration, burst int) *BurstRateLimit</code>","text":"<p>Creates a burst rate limiter.</p> <p>Parameters: - <code>limit</code>: Average operations per interval - <code>interval</code>: Time interval - <code>burst</code>: Maximum burst size (capped at 2x limit)</p>"},{"location":"features/rate-limiting/#use-cases","title":"Use Cases","text":""},{"location":"features/rate-limiting/#api-rate-limiting","title":"API Rate Limiting","text":"<pre><code>limiter := concurrent.NewRateLimiter(100, time.Minute) // 100 requests per minute\n\nfor _, url := range urls {\n    if err := limiter.Wait(ctx); err != nil {\n        return err\n    }\n\n    resp, err := http.Get(url)\n    // Process response\n}\n</code></pre>"},{"location":"features/rate-limiting/#pipeline-rate-limiting","title":"Pipeline Rate Limiting","text":"<pre><code>input := make(chan *Request)\n\n// Limit processing to 50 requests per second\noutput := concurrent.RateLimit(ctx, input, 50, time.Second)\n\nfor req := range output {\n    processRequest(req)\n}\n</code></pre>"},{"location":"features/rate-limiting/#burst-traffic-handling","title":"Burst Traffic Handling","text":"<pre><code>// Allow bursts of 1000, average 100/second\nlimiter := concurrent.NewBurstRateLimit(100, time.Second, 1000)\n\n// Handle traffic spikes gracefully\nfor req := range requests {\n    if err := limiter.Wait(ctx); err != nil {\n        return err\n    }\n    handleRequest(req)\n}\n</code></pre>"},{"location":"features/rate-limiting/#best-practices","title":"Best Practices","text":"<ol> <li>Choose appropriate limits: Balance throughput with downstream capacity</li> <li>Use burst limiters: For handling traffic spikes</li> <li>Monitor token consumption: Track how often tokens are exhausted</li> <li>Context cancellation: Always use contexts with timeouts</li> <li>Refill frequency: RateLimit automatically refills; manual limiters need periodic Refill()</li> </ol>"},{"location":"features/rate-limiting/#implementation-details","title":"Implementation Details","text":"<ul> <li>Token Bucket: Uses a buffered channel to store tokens</li> <li>Refill Strategy: Tokens are added based on elapsed time since last refill</li> <li>Thread Safety: All operations are thread-safe</li> <li>Cancellation: All operations respect context cancellation</li> </ul>"},{"location":"features/rate-limiting/#common-patterns","title":"Common Patterns","text":""},{"location":"features/rate-limiting/#background-refill","title":"Background Refill","text":"<pre><code>limiter := concurrent.NewRateLimiter(10, time.Second)\n\n// Refill in background\ngo func() {\n    ticker := time.NewTicker(100 * time.Millisecond)\n    defer ticker.Stop()\n\n    for {\n        select {\n        case &lt;-ctx.Done():\n            return\n        case &lt;-ticker.C:\n            limiter.Refill()\n        }\n    }\n}()\n\n// Use limiter\nfor {\n    if err := limiter.Wait(ctx); err != nil {\n        break\n    }\n    doWork()\n}\n</code></pre>"},{"location":"features/rate-limiting/#non-blocking-check","title":"Non-blocking Check","text":"<pre><code>if limiter.Allow() {\n    // Process immediately\n    doWork()\n} else {\n    // Rate limited, skip or queue\n    queueForLater()\n}\n</code></pre>"},{"location":"features/retry/","title":"Retry &amp; Circuit Breaker","text":"<p>The <code>concurrent</code> package provides robust retry mechanisms with exponential backoff and circuit breaker patterns for handling transient failures.</p>"},{"location":"features/retry/#retry","title":"Retry","text":""},{"location":"features/retry/#basic-retry","title":"Basic Retry","text":"<p>The <code>Retry</code> function executes a function with configurable retry logic.</p> <pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"time\"\n\n    \"github.com/logimos/concurrent\"\n)\n\nfunc main() {\n    ctx := context.Background()\n\n    config := concurrent.DefaultRetryConfig()\n    config.MaxRetries = 5\n    config.BaseDelay = 100 * time.Millisecond\n\n    err := concurrent.Retry(ctx, \"some-data\", func(ctx context.Context, data string) error {\n        // Attempt operation\n        return doSomething(data)\n    }, config)\n\n    if err != nil {\n        fmt.Printf(\"Failed after retries: %v\\n\", err)\n    }\n}\n</code></pre>"},{"location":"features/retry/#retry-configuration","title":"Retry Configuration","text":"<pre><code>type RetryConfig struct {\n    MaxRetries int           // Maximum number of retry attempts\n    BaseDelay  time.Duration // Initial delay between retries\n    MaxDelay   time.Duration // Maximum delay cap\n    Multiplier float64       // Exponential backoff multiplier\n    Jitter     bool          // Add randomness to delays\n}\n</code></pre>"},{"location":"features/retry/#default-configuration","title":"Default Configuration","text":"<pre><code>config := concurrent.DefaultRetryConfig()\n// MaxRetries: 3\n// BaseDelay: 100ms\n// MaxDelay: 5s\n// Multiplier: 2.0\n// Jitter: true\n</code></pre>"},{"location":"features/retry/#custom-configuration","title":"Custom Configuration","text":"<pre><code>config := concurrent.RetryConfig{\n    MaxRetries: 5,\n    BaseDelay:  200 * time.Millisecond,\n    MaxDelay:   10 * time.Second,\n    Multiplier: 2.5,\n    Jitter:     true,\n}\n\nerr := concurrent.Retry(ctx, item, fn, config)\n</code></pre>"},{"location":"features/retry/#retry-functions","title":"Retry Functions","text":""},{"location":"features/retry/#retrywithbackoff","title":"<code>RetryWithBackoff</code>","text":"<p>Convenience function with exponential backoff:</p> <pre><code>err := concurrent.RetryWithBackoff(ctx, item, fn, 5, 100*time.Millisecond)\n</code></pre>"},{"location":"features/retry/#retryforever","title":"<code>RetryForever</code>","text":"<p>Retries indefinitely until success or context cancellation:</p> <pre><code>ctx, cancel := context.WithTimeout(context.Background(), 5*time.Minute)\ndefer cancel()\n\nerr := concurrent.RetryForever(ctx, item, fn, 1*time.Second)\n</code></pre> <p>Warning: Use with caution and ensure proper context cancellation.</p>"},{"location":"features/retry/#withretry","title":"<code>WithRetry</code>","text":"<p>Wraps a function with retry logic:</p> <pre><code>retryableFn := concurrent.WithRetry(fn, config)\n\n// Use the wrapped function\nerr := retryableFn(ctx, item)\n</code></pre>"},{"location":"features/retry/#retryable-errors","title":"Retryable Errors","text":""},{"location":"features/retry/#marking-errors-as-retryable","title":"Marking Errors as Retryable","text":"<pre><code>import \"github.com/logimos/concurrent\"\n\n// Create a retryable error\nerr := concurrent.NewRetryableError(someError, true)\n\n// Or non-retryable\nerr := concurrent.NewRetryableError(someError, false)\n</code></pre>"},{"location":"features/retry/#checking-if-error-is-retryable","title":"Checking if Error is Retryable","text":"<pre><code>if concurrent.IsRetryable(err) {\n    // Error can be retried\n} else {\n    // Error should not be retried\n}\n</code></pre>"},{"location":"features/retry/#example-selective-retries","title":"Example: Selective Retries","text":"<pre><code>fn := func(ctx context.Context, url string) error {\n    resp, err := http.Get(url)\n    if err != nil {\n        // Network errors are retryable\n        return concurrent.NewRetryableError(err, true)\n    }\n    defer resp.Body.Close()\n\n    if resp.StatusCode == 404 {\n        // 404 is not retryable\n        return concurrent.NewRetryableError(fmt.Errorf(\"not found\"), false)\n    }\n\n    if resp.StatusCode &gt;= 500 {\n        // Server errors are retryable\n        return concurrent.NewRetryableError(fmt.Errorf(\"server error\"), true)\n    }\n\n    return nil\n}\n</code></pre>"},{"location":"features/retry/#circuit-breaker","title":"Circuit Breaker","text":"<p>Circuit breakers prevent cascading failures by stopping requests to a failing service.</p>"},{"location":"features/retry/#basic-usage","title":"Basic Usage","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"time\"\n\n    \"github.com/logimos/concurrent\"\n)\n\nfunc main() {\n    // Circuit opens after 5 failures, resets after 30 seconds\n    cb := concurrent.NewCircuitBreaker(5, 30*time.Second)\n\n    ctx := context.Background()\n\n    err := cb.Execute(ctx, func() error {\n        return callService()\n    })\n\n    if err != nil {\n        fmt.Printf(\"Error: %v\\n\", err)\n        fmt.Printf(\"Circuit state: %v\\n\", cb.State())\n    }\n}\n</code></pre>"},{"location":"features/retry/#circuit-states","title":"Circuit States","text":"<ul> <li>Closed: Normal operation, requests pass through</li> <li>Open: Circuit is open, requests fail immediately</li> <li>Half-Open: Testing if service recovered, allows one request</li> </ul>"},{"location":"features/retry/#api","title":"API","text":""},{"location":"features/retry/#newcircuitbreakerfailurethreshold-int-resettimeout-timeduration-circuitbreaker","title":"<code>NewCircuitBreaker(failureThreshold int, resetTimeout time.Duration) *CircuitBreaker</code>","text":"<p>Creates a circuit breaker.</p> <p>Parameters: - <code>failureThreshold</code>: Number of failures before opening circuit - <code>resetTimeout</code>: Time before attempting to close circuit</p>"},{"location":"features/retry/#executectx-contextcontext-fn-func-error-error","title":"<code>Execute(ctx context.Context, fn func() error) error</code>","text":"<p>Executes a function through the circuit breaker.</p>"},{"location":"features/retry/#state-circuitstate","title":"<code>State() CircuitState</code>","text":"<p>Returns the current circuit state.</p>"},{"location":"features/retry/#example-api-calls-with-circuit-breaker","title":"Example: API Calls with Circuit Breaker","text":"<pre><code>cb := concurrent.NewCircuitBreaker(5, 30*time.Second)\n\nfor _, url := range urls {\n    err := cb.Execute(ctx, func() error {\n        resp, err := http.Get(url)\n        if err != nil {\n            return err\n        }\n        defer resp.Body.Close()\n\n        if resp.StatusCode &gt;= 500 {\n            return fmt.Errorf(\"server error: %d\", resp.StatusCode)\n        }\n\n        return nil\n    })\n\n    if err != nil {\n        state := cb.State()\n        if state == concurrent.StateOpen {\n            fmt.Println(\"Circuit is open, skipping remaining requests\")\n            break\n        }\n        fmt.Printf(\"Request failed: %v\\n\", err)\n    }\n}\n</code></pre>"},{"location":"features/retry/#combining-retry-and-circuit-breaker","title":"Combining Retry and Circuit Breaker","text":"<pre><code>cb := concurrent.NewCircuitBreaker(3, 10*time.Second)\nretryConfig := concurrent.DefaultRetryConfig()\n\nfn := func(ctx context.Context, item string) error {\n    return cb.Execute(ctx, func() error {\n        return makeAPICall(item)\n    })\n}\n\nerr := concurrent.Retry(ctx, item, fn, retryConfig)\n</code></pre>"},{"location":"features/retry/#best-practices","title":"Best Practices","text":"<ol> <li>Choose retry limits: Don't retry indefinitely without bounds</li> <li>Use jitter: Prevents thundering herd problems</li> <li>Respect cancellation: Always use contexts with timeouts</li> <li>Mark errors appropriately: Distinguish retryable from non-retryable errors</li> <li>Monitor circuit state: Track circuit breaker state for observability</li> <li>Tune thresholds: Adjust failure thresholds based on your use case</li> </ol>"},{"location":"features/retry/#common-patterns","title":"Common Patterns","text":""},{"location":"features/retry/#http-request-with-retry","title":"HTTP Request with Retry","text":"<pre><code>config := concurrent.RetryConfig{\n    MaxRetries: 3,\n    BaseDelay:  1 * time.Second,\n    MaxDelay:   10 * time.Second,\n    Multiplier: 2.0,\n    Jitter:     true,\n}\n\nerr := concurrent.Retry(ctx, url, func(ctx context.Context, url string) error {\n    req, _ := http.NewRequestWithContext(ctx, \"GET\", url, nil)\n    resp, err := http.DefaultClient.Do(req)\n    if err != nil {\n        return concurrent.NewRetryableError(err, true)\n    }\n    defer resp.Body.Close()\n\n    if resp.StatusCode &gt;= 500 {\n        return concurrent.NewRetryableError(fmt.Errorf(\"server error\"), true)\n    }\n\n    return nil\n}, config)\n</code></pre>"},{"location":"features/retry/#database-operations","title":"Database Operations","text":"<pre><code>cb := concurrent.NewCircuitBreaker(5, 30*time.Second)\n\nerr := cb.Execute(ctx, func() error {\n    return db.Query(query)\n})\n\nif err != nil {\n    if cb.State() == concurrent.StateOpen {\n        // Fallback to cache or return error\n        return getFromCache()\n    }\n    return err\n}\n</code></pre>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#requirements","title":"Requirements","text":"<ul> <li>Go 1.23 or later</li> </ul>"},{"location":"getting-started/installation/#install","title":"Install","text":"<p>Install the package using <code>go get</code>:</p> <pre><code>go get github.com/logimos/concurrent\n</code></pre>"},{"location":"getting-started/installation/#import","title":"Import","text":"<p>Import the package in your Go code:</p> <pre><code>import \"github.com/logimos/concurrent\"\n</code></pre>"},{"location":"getting-started/installation/#verify-installation","title":"Verify Installation","text":"<p>Create a simple test file to verify the installation:</p> <pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n\n    \"github.com/logimos/concurrent\"\n)\n\nfunc main() {\n    ctx := context.Background()\n    data := []int{1, 2, 3}\n\n    results, err := concurrent.MapConcurrent(ctx, data, 2, func(ctx context.Context, n int) (int, error) {\n        return n * 2, nil\n    })\n\n    if err != nil {\n        panic(err)\n    }\n\n    fmt.Println(results) // [2 4 6]\n}\n</code></pre> <p>Run it:</p> <pre><code>go run main.go\n</code></pre> <p>If you see <code>[2 4 6]</code> printed, the installation is successful!</p>"},{"location":"getting-started/quick-start/","title":"Quick Start","text":"<p>This guide will help you get started with <code>concurrent</code> in minutes.</p>"},{"location":"getting-started/quick-start/#worker-pool","title":"Worker Pool","text":"<p>Process jobs concurrently with a fixed number of workers:</p> <pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"time\"\n\n    \"github.com/logimos/concurrent\"\n)\n\nfunc main() {\n    ctx := context.Background()\n\n    jobs := make(chan int)\n    pool := concurrent.NewPool(3, func(ctx context.Context, v int) (string, error) {\n        time.Sleep(100 * time.Millisecond)\n        return fmt.Sprintf(\"processed-%d\", v), nil\n    })\n\n    results := pool.Run(ctx, jobs)\n\n    // Send jobs\n    go func() {\n        for i := 0; i &lt; 10; i++ {\n            jobs &lt;- i\n        }\n        close(jobs)\n    }()\n\n    // Collect results\n    for r := range results {\n        fmt.Println(r)\n    }\n}\n</code></pre>"},{"location":"getting-started/quick-start/#pipeline","title":"Pipeline","text":"<p>Build composable data processing pipelines:</p> <pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n\n    \"github.com/logimos/concurrent\"\n)\n\nfunc main() {\n    ctx := context.Background()\n\n    input := make(chan int)\n    pipeline := concurrent.NewPipeline[int](ctx)\n\n    pipeline.AddStage(concurrent.Map(func(n int) int {\n        return n * 2\n    }))\n\n    pipeline.AddStage(concurrent.Filter(func(n int) bool {\n        return n &gt; 10\n    }))\n\n    output := pipeline.Run(input)\n\n    // Send data\n    go func() {\n        for i := 1; i &lt;= 10; i++ {\n            input &lt;- i\n        }\n        close(input)\n    }()\n\n    // Process results\n    for result := range output {\n        fmt.Println(result) // 12, 14, 16, 18, 20\n    }\n\n    pipeline.Close()\n}\n</code></pre>"},{"location":"getting-started/quick-start/#mapconcurrent","title":"MapConcurrent","text":"<p>Process a slice concurrently with bounded parallelism:</p> <pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n\n    \"github.com/logimos/concurrent\"\n)\n\nfunc main() {\n    ctx := context.Background()\n\n    data := []int{1, 2, 3, 4, 5}\n\n    results, err := concurrent.MapConcurrent(ctx, data, 3, func(ctx context.Context, n int) (int, error) {\n        return n * n, nil\n    })\n\n    if err != nil {\n        panic(err)\n    }\n\n    fmt.Println(results) // [1 4 9 16 25]\n}\n</code></pre>"},{"location":"getting-started/quick-start/#next-steps","title":"Next Steps","text":"<ul> <li>Read the Feature Documentation for detailed usage</li> <li>Check out Examples for more patterns</li> <li>Review the API Reference for complete API details</li> </ul>"}]}